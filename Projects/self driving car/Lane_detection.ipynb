{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvUP-p47B61a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from Line import Line"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def region_of_interest(img, vertices):\n",
        "    mask = np.zeros_like(img)\n",
        "    if len(img.shape) > 2:\n",
        "        channel_count = img.shape[2]\n",
        "        ignore_mask_color = (255,) * channel_count\n",
        "    else:\n",
        "        ignore_mask_color = 255\n",
        "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
        "    masked_image = cv2.bitwise_and(img, mask)\n",
        "    return masked_image, mask"
      ],
      "metadata": {
        "id": "qsnGsMpLB_VV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hough_lines_detection(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
        "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len,\n",
        "                            maxLineGap=max_line_gap)\n",
        "    return lines\n"
      ],
      "metadata": {
        "id": "jKmyTLQDCi76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def weighted_img(img, initial_img, α=0.8, β=1., λ=0.):\n",
        "    img = np.uint8(img)\n",
        "    if len(img.shape) is 2:\n",
        "        img = np.dstack((img, np.zeros_like(img), np.zeros_like(img)))\n",
        "    return cv2.addWeighted(initial_img, α, img, β, λ)"
      ],
      "metadata": {
        "id": "PLRzmHRICp_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_lane_from_candidates(line_candidates, img_shape):\n",
        "    pos_lines = [l for l in line_candidates if l.slope > 0]\n",
        "    neg_lines = [l for l in line_candidates if l.slope < 0]\n",
        "    neg_bias = np.median([l.bias for l in neg_lines]).astype(int)\n",
        "    neg_slope = np.median([l.slope for l in neg_lines])\n",
        "    x1, y1 = 0, neg_bias\n",
        "    x2, y2 = -np.int32(np.round(neg_bias / neg_slope)), 0\n",
        "    left_lane = Line(x1, y1, x2, y2)\n",
        "    lane_right_bias = np.median([l.bias for l in pos_lines]).astype(int)\n",
        "    lane_right_slope = np.median([l.slope for l in pos_lines])\n",
        "    x1, y1 = 0, lane_right_bias\n",
        "    x2, y2 = np.int32(np.round((img_shape[0] - lane_right_bias) / lane_right_slope)), img_shape[0]\n",
        "    right_lane = Line(x1, y1, x2, y2)\n",
        "    return left_lane, right_lane\n",
        "\n"
      ],
      "metadata": {
        "id": "6vWy6bfkCwLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_lane_lines(color_image, solid_lines=True):\n",
        "    color_image = cv2.resize(color_image, (960, 540))\n",
        "    img_gray = cv2.cvtColor(color_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    img_blur = cv2.GaussianBlur(img_gray, (17, 17), 0)\n",
        "\n",
        "    img_edge = cv2.Canny(img_blur, threshold1=50, threshold2=80)\n",
        "\n",
        "    detected_lines = hough_lines_detection(img=img_edge,\n",
        "                                           rho=2,\n",
        "                                           theta=np.pi / 180,\n",
        "                                           threshold=1,\n",
        "                                           min_line_len=15,\n",
        "                                           max_line_gap=5)\n",
        "\n",
        "    detected_lines = [Line(l[0][0], l[0][1], l[0][2], l[0][3]) for l in detected_lines]\n",
        "\n",
        "    if solid_lines:\n",
        "        candidate_lines = []\n",
        "        for line in detected_lines:\n",
        "                if 0.5 <= np.abs(line.slope) <= 2:\n",
        "                    candidate_lines.append(line)\n",
        "        lane_lines = compute_lane_from_candidates(candidate_lines, img_gray.shape)\n",
        "    else:\n",
        "        lane_lines = detected_lines\n",
        "\n",
        "    return lane_lines\n",
        "\n"
      ],
      "metadata": {
        "id": "5WIWz9b5C8F8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def smoothen_over_time(lane_lines):\n",
        "    avg_line_lt = np.zeros((len(lane_lines), 4))\n",
        "    avg_line_rt = np.zeros((len(lane_lines), 4))\n",
        "\n",
        "    for t in range(0, len(lane_lines)):\n",
        "        avg_line_lt[t] += lane_lines[t][0].get_coords()\n",
        "        avg_line_rt[t] += lane_lines[t][1].get_coords()\n",
        "\n",
        "    return Line(*np.mean(avg_line_lt, axis=0)), Line(*np.mean(avg_line_rt, axis=0))\n"
      ],
      "metadata": {
        "id": "WIywXc0gDOo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def color_frame_pipeline(frames, solid_lines=True, temporal_smoothing=True):\n",
        "    is_videoclip = len(frames) > 0\n",
        "\n",
        "    img_h, img_w = frames[0].shape[0], frames[0].shape[1]\n",
        "\n",
        "    lane_lines = []\n",
        "    for t in range(0, len(frames)):\n",
        "        inferred_lanes = get_lane_lines(color_image=frames[t], solid_lines=solid_lines)\n",
        "        lane_lines.append(inferred_lanes)\n",
        "\n",
        "    if temporal_smoothing and solid_lines:\n",
        "        lane_lines = smoothen_over_time(lane_lines)\n",
        "    else:\n",
        "        lane_lines = lane_lines[0]\n",
        "\n",
        "    line_img = np.zeros(shape=(img_h, img_w))\n",
        "\n",
        "    for lane in lane_lines:\n",
        "        lane.draw(line_img)\n",
        "\n",
        "    vertices = np.array([[(50, img_h),\n",
        "                          (450, 310),\n",
        "                          (490, 310),\n",
        "                          (img_w - 50, img_h)]],\n",
        "                        dtype=np.int32)\n",
        "    img_masked, _ = region_of_interest(line_img, vertices)\n",
        "    img_color = frames[-1] if is_videoclip else frames[0]\n",
        "    img_blend = weighted_img(img_masked, img_color, α=0.8, β=1., λ=0.)\n",
        "\n",
        "    return img_blend"
      ],
      "metadata": {
        "id": "e6XxoDAxDWrM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}